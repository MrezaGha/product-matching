{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import csv\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten laden Datensatz_A\n",
    "data_path_a = r'daten/amazon_data1.xlsx'\n",
    "data_db_a = pd.read_excel(data_path_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten laden Datensatz_B\n",
    "data_path_b = r'daten/otto_data1.xlsx'\n",
    "data_db_b = pd.read_excel(data_path_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data(df, columns):\n",
    "    \"\"\"\n",
    "    Bereitet den Datensatz für die Analyse vor, indem nicht benötigte Spalten entfernt und Textdaten normalisiert werden.\n",
    "\n",
    "    :param df: Pandas DataFrame, der Datensatz.\n",
    "    :param columns_to_remove: Liste von Spaltennamen, die entfernt werden sollen.\n",
    "    :param columns: Liste von Textspalten, die normalisiert werden sollen.\n",
    "    :return: Bereinigter und normalisierter DataFrame.\n",
    "    \"\"\"\n",
    "    # Entfernen von Spalten mit vielen fehlenden Werten\n",
    "    # df = df.drop(columns=columns_to_remove)\n",
    "    df = df[columns]\n",
    "\n",
    "    # Normalisierung und Bereinigung von Textdaten und Entfernung von Leerzeichen\n",
    "    for col in columns:\n",
    "        # df[col] = df[col].str.replace(r'[\\|\\-]', ' ', regex=True)\n",
    "        df.loc[:, col] = df[col].str.replace(r'[\\|\\-]', ' ', regex=True)\n",
    "        # mehrere aufeinanderer folgen der Leerzeichen wegbekomme \n",
    "        df.loc[:, col] = df[col].str.replace(r'\\s+', ' ', regex=True)\n",
    "        # df[col] = df[col].str.lower().str.replace(r\"[^a-z0-9äöüß\\s]\", \"\", regex=True)\n",
    "        df.loc[:, col] = df[col].str.lower().str.replace(r\"[^a-z0-9äöüß%\\s]\", \"\", regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_data(df, duplicate_file):\n",
    "    \"\"\"\n",
    "    Entfernt die Daten die doppelt in eine Datensatz vorkommen\n",
    "    \n",
    "    :param df: Data frame, der Datensatz.\n",
    "    :param duplicate_file: eine Liste von Duplikaten, die in dem Datensatz mehrfach vorkommen.\n",
    "    \"\"\"\n",
    "    \n",
    "    duplicate_rows = df[df.duplicated(keep='first')]\n",
    "    data = df.drop_duplicates(keep='first')\n",
    "    duplicate_rows.to_excel(duplicate_file)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mohammadrezaghassemzadeh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(df, columns):\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            df[column + '_clean'] = df[column].apply(lambda x: ' '.join([word for word in x.split() if word.lower() \n",
    "                                                                         not in stop_words]) if isinstance(x, str) else x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate löschen\n",
    "path_duplicate_data = r\"/Users/mohammadrezaghassemzadeh/Desktop/p-matching/product-matching/daten/amazon_duplicate.xlsx\"\n",
    "data_db_a = remove_duplicate_data(data_db_a, path_duplicate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für Datensatz A\n",
    "# Anzuwendende Spalten für Entfernung und Normalisierung\n",
    "# Diese Code Cell sollte an der Anwendung und Daten angepasst werden\n",
    "\n",
    "# Spalten die nicht fuer den Framework relevant sind, sollte hier angegeben werden\n",
    "# columns_to_remove = ['promotion_s', 'title_t', 'colour_technical_txt', 'brand_s', \n",
    "#                      'customer_rating_s', 'stars_s', 'energyEfficiency_s', \n",
    "#                      'category_name_detail_s', 'EAN_s', 'price_s', 'price_old_s']\n",
    "\n",
    "# Heirbei handelt es sich um Spalten, die für die Analyse relevant sind\n",
    "text_columns = ['NAME','DESCRIPTION']\n",
    "\n",
    "data_db_a = prepare_data(data_db_a, text_columns)\n",
    "\n",
    "# data_db_a = remove_stopwords(data_db_a, text_columns)\n",
    "\n",
    "# data_db_a.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Für Datensatz A\n",
    "# Anzuwendende Spalten für Entfernung und Normalisierung\n",
    "# Diese Code Cell sollte an der Anwendung und Daten angepasst werden\n",
    "\n",
    "# Spalten die nicht fuer den Framework relevant sind, sollte hier angegeben werden\n",
    "# columns_to_remove = ['promotion_s', 'title_t', 'colour_technical_txt', 'brand_s', \n",
    "#                      'customer_rating_s', 'stars_s', 'energyEfficiency_s', \n",
    "#                      'category_name_detail_s', 'EAN_s', 'price_s', 'price_old_s']\n",
    "\n",
    "# Heirbei handelt es sich um Spalten, die für die Analyse relevant sind\n",
    "text_columns = ['NAME','DESCRIPTION']\n",
    "\n",
    "data_db_b = prepare_data(data_db_b, text_columns)\n",
    "\n",
    "# data_db_b = remove_stopwords(data_db_b, text_columns)\n",
    "\n",
    "# data_db_b.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_db_a.to_excel('daten/amazon_datenbereinigt.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_db_b.to_excel('daten/otto_datenbereinigt.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('bachelorarbeit': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a6dcd5c1c1941ffa60e357ee1f7133a2c552a4a7fb1e2a5b3b962f361695b81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
